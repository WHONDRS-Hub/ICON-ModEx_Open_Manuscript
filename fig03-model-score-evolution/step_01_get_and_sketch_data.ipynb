{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0318950a",
   "metadata": {},
   "source": [
    "# Assessing the ICON-ModEx ML models\n",
    "\n",
    "## How does the model score change with each ICON-ModEx iteration?\n",
    "This notebook will harvest the data from the `dynamic-learning-rivers` repository to make a plot showing the evolution of the ML models as more traininig data is added.\n",
    "\n",
    "## Important behind the scenes information\n",
    "Here, I am assuming that this notebook is running in a Linux context (e.g. pull a [container that runs a local Jupyter server](https://hub.docker.com/r/jupyter/datascience-notebook) and open the notebook therein). This code will switch branches within a repository that it downloads from GitHub to load the data for side by side comparisions. It will then delete the source repository and retain only the harvested data used for plotting. The harvested data will be saved alongside this notebook here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bfa85-63de-4d6d-97c4-928490aa37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once at start of notebook if these \n",
    "# packages are not already installed\n",
    "! conda install -y -q pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2526f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae95d7",
   "metadata": {},
   "source": [
    "## Clone source repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc380de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org='parallelworks'\n",
    "repo='dynamic-learning-rivers'\n",
    "!git clone https://github.com/{org}/{repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3974b3",
   "metadata": {},
   "source": [
    "## Grab data and save to CSV\n",
    "Here we want to track the model score over ModEx iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325fb9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start from fresh! Delete any .csv files that may already be here\n",
    "!rm -f ICON-ModEx_automated_iterations.csv\n",
    "\n",
    "# List the branches we want to work with\n",
    "list_branches_scale = [\n",
    "    'Jul-2022',\n",
    "    'Aug-2022',\n",
    "    'Sep-2022',\n",
    "    'Oct-2022',\n",
    "    'Nov-2022',\n",
    "    'Dec-2022',\n",
    "    'Jan-2023',\n",
    "    'Feb-2023',\n",
    "    'Mar-2023',\n",
    "    'ICON-ModEx-v2.1-April-2023-replicate-01',\n",
    "    'ICON-ModEx-v2.1-April-2023-replicate-02',\n",
    "    'May-2023',\n",
    "    'June-2023',\n",
    "    'Jul-2023',\n",
    "    'August-2023',\n",
    "    'Sep-2023',\n",
    "    'Oct-2023',\n",
    "    'Nov-2023']\n",
    "\n",
    "list_branches_log10 = [\n",
    "    'Sep-2019-log10',\n",
    "    'Jul-2022-log10',\n",
    "    'Aug-2022-log10',\n",
    "    'Sep-2022-log10',\n",
    "    'Oct-2022-log10',\n",
    "    'Nov-2022-log10',\n",
    "    'Dec-2022-log10',\n",
    "    'Jan-2023-log10',\n",
    "    'Feb-2023-log10',\n",
    "    'Mar-2023-log10',\n",
    "    'Apr-2023-log10',\n",
    "    'May-2023-log10',\n",
    "    'June-2023-log10',\n",
    "    'Jul-2023-log10',\n",
    "    'August-2023-log10',\n",
    "    'Sep-2023-log10',\n",
    "    'Oct-2023-log10',\n",
    "    'Nov-2023-log10',\n",
    "    'Nov-2023-log10-DO-update-correct']\n",
    "\n",
    "# Initialize empty dataframes\n",
    "icon_modex_log10 = pd.DataFrame(columns=['hold-out-avg','hold-out-std','ntrain'])\n",
    "icon_modex_scale = pd.DataFrame(columns=['hold-out-avg','hold-out-std','ntrain'])\n",
    "\n",
    "#=======================================\n",
    "# Gather data over the standard branches\n",
    "#=======================================\n",
    "for bb,branch in enumerate(list_branches_scale):\n",
    "    \n",
    "    # Change to the requested branch\n",
    "    !cd dynamic-learning-rivers; git checkout {branch}\n",
    "    \n",
    "    # We want to get the mean and std of the score and plot that vs the number of inputs to train.\n",
    "    # Each dot will be an ICON-ModEx iteration.\n",
    "    \n",
    "    # This file summarizes the holdout score for all the\n",
    "    # Superlearners for each ICON-ModEx iteration.\n",
    "    holdout_score = pd.read_csv(\n",
    "        repo+'/output_data/holdout_score.txt', \n",
    "        sep=':', \n",
    "        names=['Value','Number'], \n",
    "        index_col='Value' )\n",
    "    #holdout_score = pd.read_csv(repo+'/output_data/holdout_score.txt', sep=':')\n",
    "    \n",
    "    # This file lists the total number of data available\n",
    "    # (of which 25% is split to the testing set)\n",
    "    # Some of these points are dropped during training due to\n",
    "    # missing values. A better measure of the actual number of\n",
    "    # data points used to train the models is in the \n",
    "    # alternative file which is present after all the \n",
    "    # preprocessing steps are completed.\n",
    "    # RAW INPUT\n",
    "    #input_data = pd.read_csv(repo+'/input_data/ICON-ModEx_Data.csv')\n",
    "    # PREPROCESSED INPUT\n",
    "    input_data = pd.read_csv(repo+'/scripts/prep_06_output_final_train.csv')\n",
    "    \n",
    "    icon_modex_scale.loc[len(icon_modex_scale.index)] = [\n",
    "        holdout_score.loc['Avg',:].values[0],\n",
    "        holdout_score.loc['Std',:].values[0],\n",
    "        len(input_data.index)\n",
    "    ]\n",
    "    \n",
    "    # We could also grab the histogram of CONUS predictions to \n",
    "    # check for an evolution of bias over time\n",
    "    # Grab code from the Figure-2 harvestor notebook if needed.    \n",
    "\n",
    "#=====================================\n",
    "# Gather data over the -log10 branches\n",
    "#=====================================\n",
    "for bb,branch in enumerate(list_branches_log10):\n",
    "    \n",
    "    # Change to the requested branch\n",
    "    !cd dynamic-learning-rivers; git checkout {branch}\n",
    "    \n",
    "    # We want to get the mean and std of the score and plot that vs the number of inputs to train.\n",
    "    # Each dot will be an ICON-ModEx iteration.\n",
    "    \n",
    "    # This file summarizes the holdout score for all the\n",
    "    # Superlearners for each ICON-ModEx iteration.\n",
    "    holdout_score = pd.read_csv(\n",
    "        repo+'/output_data/holdout_score.txt', \n",
    "        sep=':', \n",
    "        names=['Value','Number'], \n",
    "        index_col='Value' )\n",
    "    #holdout_score = pd.read_csv(repo+'/output_data/holdout_score.txt', sep=':')\n",
    "    \n",
    "    # This file lists the total number of data available\n",
    "    # (of which 25% is split to the testing set)\n",
    "    # RAW INPUT (see note above)\n",
    "    #input_data = pd.read_csv(repo+'/input_data/ICON-ModEx_Data.csv')\n",
    "    # PREPROCESSED INPUT\n",
    "    input_data = pd.read_csv(repo+'/scripts/prep_06_output_final_train.csv')\n",
    "    \n",
    "    icon_modex_log10.loc[len(icon_modex_log10.index)] = [\n",
    "        holdout_score.loc['Avg',:].values[0],\n",
    "        holdout_score.loc['Std',:].values[0],\n",
    "        len(input_data.index)\n",
    "    ]\n",
    "    \n",
    "    # We could also grab the histogram of CONUS predictions to check for an evolution of bias over time\n",
    "    # Grab code from the Figure-2 harvestor notebook if needed.\n",
    "\n",
    "# Save the intermediate results for reproducibility and\n",
    "# offline plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679564c",
   "metadata": {},
   "source": [
    "# Load and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d3155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icon_modex_manual = pd.read_csv('ICON-ModEx_manual_iterations.csv')\n",
    "\n",
    "# These iterations are the very first automated iterations\n",
    "# presented at AGU2022. They were done in a \"hindcast mode\"\n",
    "# to be able to compare to the manual iterations.\n",
    "icon_modex_raw = pd.read_csv('ICON-ModEx_automated_iterations_raw.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.errorbar(\n",
    "    icon_modex_manual['ntrain'],\n",
    "    icon_modex_manual[['hold-out','cv_avg']].max(axis=1),\n",
    "    yerr=icon_modex_manual['cv_std'],\n",
    "    fmt='k+',\n",
    "    ecolor='lightgray',\n",
    "    capsize=0)\n",
    "#plt.errorbar(\n",
    "#    icon_modex_raw['ntrain'],\n",
    "#    icon_modex_raw['hold-out-avg'],\n",
    "#    yerr=icon_modex_raw['hold-out-std'],\n",
    "#    fmt='ko-',\n",
    "#    ecolor='r',\n",
    "#    capsize=5)\n",
    "plt.errorbar(\n",
    "    icon_modex_scale['ntrain'],\n",
    "    icon_modex_scale['hold-out-avg'],\n",
    "    icon_modex_scale['hold-out-std'],\n",
    "    fmt='ko-',\n",
    "    ecolor='r',\n",
    "    capsize=5)\n",
    "plt.errorbar(\n",
    "    icon_modex_log10['ntrain'],\n",
    "    icon_modex_log10['hold-out-avg'],\n",
    "    icon_modex_log10['hold-out-std'],\n",
    "    fmt='ks',\n",
    "    ecolor='b',\n",
    "    capsize=5)\n",
    "ax.grid()\n",
    "plt.ylabel('ML Model Score (R^2)')\n",
    "plt.xlabel('Number of samples in training data set')\n",
    "plt.legend(['Manual iterations','ModEx - live','ModEx - log10 hindcast'])\n",
    "plt.savefig('ICON_ModEx_summary.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6b41f",
   "metadata": {},
   "source": [
    "**Figure Caption:** Manual runs were done before AGU2022 as ICON-ModEx ramped up. The \"live\" iterations are the actual ICON-ModEx ML models that generated the results that were used for making decisions of which sites to sample. The hindcast iterations use a log10 filter because this reduces the bias of the ML models (see histogram analysis of Fig2). The big jump in the live iterations is due to the scaling of the respiration rate data with respect to the volume of the analysis container (need to double check this) (i.e. \"Normalization\") in June of 2023. The hindcast runs all take advantage of the scaling and the log10 transform to provide an apples-to-apples comparision of the progress of the ICON-ModEx iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161c6fc-ca91-46d5-ad67-34f9fe8fbdab",
   "metadata": {},
   "source": [
    "# Load and plot simplified version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162917f8-a430-4b13-a79c-bb8ecf3c4c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icon_modex_manual = pd.read_csv('ICON-ModEx_manual_iterations.csv')\n",
    "\n",
    "# These iterations are the very first automated iterations\n",
    "# presented at AGU2022. They were done in a \"hindcast mode\"\n",
    "# to be able to compare to the manual iterations.\n",
    "icon_modex_raw = pd.read_csv('ICON-ModEx_automated_iterations_raw.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.errorbar(\n",
    "    icon_modex_manual['ntrain'],\n",
    "    icon_modex_manual[['hold-out','cv_avg']].max(axis=1),\n",
    "    yerr=icon_modex_manual['cv_std'],\n",
    "    fmt='k+',\n",
    "    ecolor='lightgray',\n",
    "    capsize=0)\n",
    "plt.errorbar(\n",
    "    icon_modex_log10['ntrain'],\n",
    "    icon_modex_log10['hold-out-avg'],\n",
    "    icon_modex_log10['hold-out-std'],\n",
    "    fmt='ks',\n",
    "    ecolor='b',\n",
    "    capsize=5)\n",
    "ax.grid()\n",
    "plt.ylabel('ML Model Score (R^2)')\n",
    "plt.xlabel('Number of samples in training data set')\n",
    "plt.legend(['Manual pre-ModEx iterations','ModEx iterations'])\n",
    "plt.savefig('ICON_ModEx_summary_simplified.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b2da1-16b6-406e-b09b-f272ce16e349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
