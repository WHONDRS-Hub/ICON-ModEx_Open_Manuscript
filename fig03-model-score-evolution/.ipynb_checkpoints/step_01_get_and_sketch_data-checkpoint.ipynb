{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0318950a",
   "metadata": {},
   "source": [
    "# Assessing the ICON-ModEx ML models\n",
    "\n",
    "## How does the model score change with each ICON-ModEx iteration?\n",
    "This notebook will harvest the data from the `dynamic-learning-rivers` repository to make a plot showing the evolution of the ML models as more traininig data is added.\n",
    "\n",
    "## Important behind the scenes information\n",
    "Here, I am assuming that this notebook is running in a Linux context (e.g. pull a [container that runs a local Jupyter server](https://hub.docker.com/r/jupyter/datascience-notebook) and open the notebook therein). This code will switch branches within a repository that it downloads from GitHub to load the data for side by side comparisions. It will then delete the source repository and retain only the harvested data used for plotting. The harvested data will be saved alongside this notebook here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bfa85-63de-4d6d-97c4-928490aa37da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run once at start of notebook if these \n",
    "# packages are not already installed\n",
    "! conda install -y -q pandas numpy matplotlib\n",
    "! conda install -y -q papermill\n",
    "! conda install -y -q jupytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2526f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import papermill as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert .Rmd subscript to .ipynb\n",
    "#! jupytext --to notebook make_scatter_plot.Rmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae95d7",
   "metadata": {},
   "source": [
    "## Clone source repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc380de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'dynamic-learning-rivers' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "repo_prefix = '~/tmp/'\n",
    "repo_org='parallelworks'\n",
    "repo_name='dynamic-learning-rivers'\n",
    "repo_url = 'https://github.com/'+repo_org+'/'+repo_name\n",
    "\n",
    "! mkdir -p {repo_prefix}\n",
    "! cd {repo_prefix}; git clone {repo_url}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3974b3",
   "metadata": {},
   "source": [
    "## Grab data and save to CSV\n",
    "Here we want to track the model score over ModEx iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a34ce113-6aaf-4815-a6f2-cccb2bfa3846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functionalize all the data preporatory steps based on the\n",
    "# branch name.\n",
    "def prep_data_on_branch(repo_prefix=repo_prefix, repo_name=repo_name, branch_name='main'):\n",
    "\n",
    "    # Change to the requested branch\n",
    "    ! cd {repo_prefix}/{repo_name}; git checkout {branch_name}\n",
    "    \n",
    "    # Create a working directory for this branch\n",
    "    ! mkdir -p ./intermediate_branch_data/{branch_name}\n",
    "    \n",
    "    # Load data we want to prepare/merge/preprocess\n",
    "    data_prefix=repo_prefix+'/'+repo_name\n",
    "    main_input = pd.read_csv(data_prefix+\"/scripts/prep_01_output_train.csv\")\n",
    "    avg_output = pd.read_csv(data_prefix+'/scripts/post_01_output_ml_predict_avg.csv')\n",
    "    std_output = pd.read_csv(data_prefix+'/scripts/post_01_output_ml_predict_std.csv')\n",
    "    \n",
    "    # Use Sample_ID as the index so files can be merged on this value\n",
    "    main_input.set_index('Sample_ID',inplace=True)\n",
    "    avg_output.set_index('Sample_ID',inplace=True)\n",
    "    std_output.set_index('Sample_ID',inplace=True)\n",
    "\n",
    "    # Merge files\n",
    "    avg_merge = pd.merge(\n",
    "        main_input,\n",
    "        avg_output, \n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=['_obs','_pre_avg'])\n",
    "\n",
    "    all_merge = pd.merge(\n",
    "        avg_merge,\n",
    "        std_output, \n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=['','_pre_std'])\n",
    "\n",
    "    predict_and_obs_merge = pd.merge(\n",
    "        avg_output,\n",
    "        std_output,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=['_pre_avg','_pre_std'])\n",
    "    \n",
    "    # Write intermediate output files\n",
    "    avg_merge.to_csv('intermediate_branch_data/'+branch_name+'/output_obs_avgpre_merged.csv',mode='w')\n",
    "    all_merge.to_csv('intermediate_branch_data/'+branch_name+'/output_obs_avgpre_stdpre_merged.csv',mode='w')\n",
    "    predict_and_obs_merge.to_csv('intermediate_branch_data/'+branch_name+'/output_all_sites_avgpre_stdpre_merged.csv',mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "325fb9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translator for 'R' language does not support parameter introspection.\n",
      "Passed unknown parameter: work_dir\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3729977c952e41bb8ecbc436e862437c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/22 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution halted\n"
     ]
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [4]\":\nError in library(tidyverse): there is no package called ‘tidyverse’\nTraceback:\n\n1. library(tidyverse)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrm -f ICON-ModEx_automated_iterations.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# WORKING HERE! Move to inside the loop!\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Use Papermill to launch a notebook\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# To list available kernels,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#   jupyter kernelspec list\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# The working directory was created by prep_data_on_branch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_notebook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmake_scatter_plot.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_scatter_plot.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./intermediate_branch_data/Nov-2023-log10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# List the branches we want to work with\u001b[39;00m\n\u001b[1;32m     17\u001b[0m list_branches_scale \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJul-2022\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAug-2022\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOct-2023\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNov-2023\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/pw/.miniconda3c/lib/python3.11/site-packages/papermill/execute.py:131\u001b[0m, in \u001b[0;36mexecute_notebook\u001b[0;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         nb \u001b[38;5;241m=\u001b[39m papermill_engines\u001b[38;5;241m.\u001b[39mexecute_notebook_with_engine(\n\u001b[1;32m    117\u001b[0m             engine_name,\n\u001b[1;32m    118\u001b[0m             nb,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    128\u001b[0m         )\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mraise_for_execution_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Write final output in case the engine didn't write it on cell completion.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m write_ipynb(nb, output_path)\n",
      "File \u001b[0;32m~/pw/.miniconda3c/lib/python3.11/site-packages/papermill/execute.py:251\u001b[0m, in \u001b[0;36mraise_for_execution_errors\u001b[0;34m(nb, output_path)\u001b[0m\n\u001b[1;32m    248\u001b[0m nb\u001b[38;5;241m.\u001b[39mcells\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, error_msg_cell)\n\u001b[1;32m    250\u001b[0m write_ipynb(nb, output_path)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [4]\":\nError in library(tidyverse): there is no package called ‘tidyverse’\nTraceback:\n\n1. library(tidyverse)\n"
     ]
    }
   ],
   "source": [
    "# Start from fresh! Delete any .csv files that may already be here\n",
    "!rm -f ICON-ModEx_automated_iterations.csv\n",
    "\n",
    "# WORKING HERE! Move to inside the loop!\n",
    "# Use Papermill to launch a notebook\n",
    "# To list available kernels,\n",
    "#   jupyter kernelspec list\n",
    "# The working directory was created by prep_data_on_branch\n",
    "pm.execute_notebook(\n",
    "    'make_scatter_plot.ipynb',\n",
    "    'log_scatter_plot.ipynb',\n",
    "    parameters=dict(work_dir='./intermediate_branch_data/Nov-2023-log10'),\n",
    "    kernel_name='ir'\n",
    ")\n",
    "\n",
    "# List the branches we want to work with\n",
    "list_branches_scale = [\n",
    "    'Jul-2022',\n",
    "    'Aug-2022',\n",
    "    'Sep-2022',\n",
    "    'Oct-2022',\n",
    "    'Nov-2022',\n",
    "    'Dec-2022',\n",
    "    'Jan-2023',\n",
    "    'Feb-2023',\n",
    "    'Mar-2023',\n",
    "    'ICON-ModEx-v2.1-April-2023-replicate-01',\n",
    "    'ICON-ModEx-v2.1-April-2023-replicate-02',\n",
    "    'May-2023',\n",
    "    'June-2023',\n",
    "    'Jul-2023',\n",
    "    'August-2023',\n",
    "    'Sep-2023',\n",
    "    'Oct-2023',\n",
    "    'Nov-2023']\n",
    "\n",
    "list_branches_log10 = [\n",
    "    'Dec-2021-log10',\n",
    "    'Sep-2019-log10',\n",
    "    'Jul-2022-log10',\n",
    "    'Aug-2022-log10',\n",
    "    'Sep-2022-log10',\n",
    "    'Oct-2022-log10',\n",
    "    'Nov-2022-log10',\n",
    "    'Dec-2022-log10',\n",
    "    'Jan-2023-log10',\n",
    "    'Feb-2023-log10',\n",
    "    'Mar-2023-log10',\n",
    "    'Apr-2023-log10',\n",
    "    'May-2023-log10',\n",
    "    'June-2023-log10',\n",
    "    'Jul-2023-log10',\n",
    "    'August-2023-log10',\n",
    "    'Sep-2023-log10',\n",
    "    'Oct-2023-log10',\n",
    "    'Nov-2023-log10',\n",
    "    'Nov-2023-log10-DO-update-correct']\n",
    "\n",
    "# Initialize empty dataframes\n",
    "icon_modex_log10 = pd.DataFrame(columns=['hold-out-avg','hold-out-std','ntrain'])\n",
    "icon_modex_scale = pd.DataFrame(columns=['hold-out-avg','hold-out-std','ntrain'])\n",
    "\n",
    "#=======================================\n",
    "# Gather data over the standard branches\n",
    "#=======================================\n",
    "for bb,branch in enumerate(list_branches_scale):\n",
    "    \n",
    "    # Change to the requested branch\n",
    "    # We do not need to prep_data_on_branch for the non-log10 branches\n",
    "    # since we are not plotting the animation of the scatter \n",
    "    #prep_data_on_branch(repo_prefix=repo_prefix, repo_name=repo_name, branch_name=branch)\n",
    "    !cd {repo_prefix}/{repo_name}; git checkout {branch}\n",
    "    \n",
    "    # We want to get the mean and std of the score and plot that vs the number of inputs to train.\n",
    "    # Each dot will be an ICON-ModEx iteration.\n",
    "    \n",
    "    # This file summarizes the holdout score for all the\n",
    "    # Superlearners for each ICON-ModEx iteration.\n",
    "    holdout_score = pd.read_csv(\n",
    "        repo_prefix+'/'+repo_name+'/output_data/holdout_score.txt', \n",
    "        sep=':', \n",
    "        names=['Value','Number'], \n",
    "        index_col='Value' )\n",
    "    #holdout_score = pd.read_csv(repo+'/output_data/holdout_score.txt', sep=':')\n",
    "    \n",
    "    # This file lists the total number of data available\n",
    "    # (of which 25% is split to the testing set)\n",
    "    # Some of these points are dropped during training due to\n",
    "    # missing values. A better measure of the actual number of\n",
    "    # data points used to train the models is in the \n",
    "    # alternative file which is present after all the \n",
    "    # preprocessing steps are completed.\n",
    "    # RAW INPUT\n",
    "    #input_data = pd.read_csv(repo+'/input_data/ICON-ModEx_Data.csv')\n",
    "    # PREPROCESSED INPUT\n",
    "    input_data = pd.read_csv(repo_prefix+'/'+repo_name+'/scripts/prep_06_output_final_train.csv')\n",
    "    \n",
    "    icon_modex_scale.loc[len(icon_modex_scale.index)] = [\n",
    "        holdout_score.loc['Avg',:].values[0],\n",
    "        holdout_score.loc['Std',:].values[0],\n",
    "        len(input_data.index)\n",
    "    ]\n",
    "    \n",
    "    # We could also grab the histogram of CONUS predictions to \n",
    "    # check for an evolution of bias over time\n",
    "    # Grab code from the Figure-2 harvestor notebook if needed.    \n",
    "\n",
    "#=====================================\n",
    "# Gather data over the -log10 branches\n",
    "#=====================================\n",
    "for bb,branch in enumerate(list_branches_log10):\n",
    "    \n",
    "    # Change to the requested branch\n",
    "    prep_data_on_branch(repo_prefix=repo_prefix, repo_name=repo_name, branch_name=branch)\n",
    "    #!cd {repo_prefix}/{repo_name}; git checkout {branch}\n",
    "    \n",
    "    # We want to get the mean and std of the score and plot that vs the number of inputs to train.\n",
    "    # Each dot will be an ICON-ModEx iteration.\n",
    "    \n",
    "    # This file summarizes the holdout score for all the\n",
    "    # Superlearners for each ICON-ModEx iteration.\n",
    "    holdout_score = pd.read_csv(\n",
    "        repo_prefix+'/'+repo_name+'/output_data/holdout_score.txt', \n",
    "        sep=':', \n",
    "        names=['Value','Number'], \n",
    "        index_col='Value' )\n",
    "    #holdout_score = pd.read_csv(repo+'/output_data/holdout_score.txt', sep=':')\n",
    "    \n",
    "    # This file lists the total number of data available\n",
    "    # (of which 25% is split to the testing set)\n",
    "    # RAW INPUT (see note above)\n",
    "    #input_data = pd.read_csv(repo+'/input_data/ICON-ModEx_Data.csv')\n",
    "    # PREPROCESSED INPUT\n",
    "    input_data = pd.read_csv(repo_prefix+'/'+repo_name+'/scripts/prep_06_output_final_train.csv')\n",
    "    \n",
    "    icon_modex_log10.loc[len(icon_modex_log10.index)] = [\n",
    "        holdout_score.loc['Avg',:].values[0],\n",
    "        holdout_score.loc['Std',:].values[0],\n",
    "        len(input_data.index)\n",
    "    ]\n",
    "    \n",
    "    # We could also grab the histogram of CONUS predictions to check for an evolution of bias over time\n",
    "    # Grab code from the Figure-2 harvestor notebook if needed.\n",
    "\n",
    "# Save the intermediate results for reproducibility and\n",
    "# offline plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679564c",
   "metadata": {},
   "source": [
    "# Load and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d3155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icon_modex_manual = pd.read_csv('ICON-ModEx_manual_iterations.csv')\n",
    "\n",
    "# These iterations are the very first automated iterations\n",
    "# presented at AGU2022. They were done in a \"hindcast mode\"\n",
    "# to be able to compare to the manual iterations.\n",
    "icon_modex_raw = pd.read_csv('ICON-ModEx_automated_iterations_raw.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.errorbar(\n",
    "    icon_modex_manual['ntrain'],\n",
    "    icon_modex_manual[['hold-out','cv_avg']].max(axis=1),\n",
    "    yerr=icon_modex_manual['cv_std'],\n",
    "    fmt='k+',\n",
    "    ecolor='lightgray',\n",
    "    capsize=0)\n",
    "#plt.errorbar(\n",
    "#    icon_modex_raw['ntrain'],\n",
    "#    icon_modex_raw['hold-out-avg'],\n",
    "#    yerr=icon_modex_raw['hold-out-std'],\n",
    "#    fmt='ko-',\n",
    "#    ecolor='r',\n",
    "#    capsize=5)\n",
    "plt.errorbar(\n",
    "    icon_modex_scale['ntrain'],\n",
    "    icon_modex_scale['hold-out-avg'],\n",
    "    icon_modex_scale['hold-out-std'],\n",
    "    fmt='ko-',\n",
    "    ecolor='r',\n",
    "    capsize=5)\n",
    "plt.errorbar(\n",
    "    icon_modex_log10['ntrain'],\n",
    "    icon_modex_log10['hold-out-avg'],\n",
    "    icon_modex_log10['hold-out-std'],\n",
    "    fmt='ks',\n",
    "    ecolor='b',\n",
    "    capsize=5)\n",
    "ax.grid()\n",
    "plt.ylabel('Avg ML Model Score of Training data set (R2)')\n",
    "plt.xlabel('Total number of samples in input data set')\n",
    "plt.legend(['Manual iterations','ModEx - live','ModEx - log10 hindcast'])\n",
    "plt.savefig('ICON_ModEx_summary.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf6b41f",
   "metadata": {},
   "source": [
    "**Figure Caption:** Manual runs were done before AGU2022 as ICON-ModEx ramped up. The \"live\" iterations are the actual ICON-ModEx ML models that generated the results that were used for making decisions of which sites to sample. The hindcast iterations use a log10 filter because this reduces the bias of the ML models (see histogram analysis of Fig2). The big jump in the live iterations is due to the scaling of the respiration rate data with respect to the volume of the analysis container (need to double check this) (i.e. \"Normalization\") in June of 2023. The hindcast runs all take advantage of the scaling and the log10 transform to provide an apples-to-apples comparision of the progress of the ICON-ModEx iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161c6fc-ca91-46d5-ad67-34f9fe8fbdab",
   "metadata": {},
   "source": [
    "# Load and plot simplified version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162917f8-a430-4b13-a79c-bb8ecf3c4c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "icon_modex_manual = pd.read_csv('ICON-ModEx_manual_iterations.csv')\n",
    "\n",
    "# These iterations are the very first automated iterations\n",
    "# presented at AGU2022. They were done in a \"hindcast mode\"\n",
    "# to be able to compare to the manual iterations.\n",
    "icon_modex_raw = pd.read_csv('ICON-ModEx_automated_iterations_raw.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.errorbar(\n",
    "    icon_modex_manual['ntrain'],\n",
    "    icon_modex_manual[['hold-out','cv_avg']].max(axis=1),\n",
    "    yerr=icon_modex_manual['cv_std'],\n",
    "    fmt='k+',\n",
    "    ecolor='lightgray',\n",
    "    capsize=0)\n",
    "plt.errorbar(\n",
    "    icon_modex_log10['ntrain'],\n",
    "    icon_modex_log10['hold-out-avg'],\n",
    "    icon_modex_log10['hold-out-std'],\n",
    "    fmt='ks',\n",
    "    ecolor='b',\n",
    "    capsize=5)\n",
    "ax.grid()\n",
    "plt.ylabel('Avg ML Model Score of Training data set (R2)')\n",
    "plt.xlabel('Total number of samples in input data set')\n",
    "plt.legend(['Manual pre-ModEx iterations','ModEx iterations'])\n",
    "plt.savefig('ICON_ModEx_summary_simplified.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f61f73-7f9a-4a4f-a595-376cb6db4d64",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f071e8-b1a1-4129-8058-291779341c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rm -fv make_scatter_plot.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c23e15-1094-4c6a-81ce-2be61ea06c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
