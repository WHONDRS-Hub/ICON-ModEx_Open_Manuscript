{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944285e4",
   "metadata": {},
   "source": [
    "# Plot feature permutation importance (FPI) results\n",
    "\n",
    "This notebook will visualize/consolidate the FPI results of the machine learning runs (organized in different branches) in this repositiory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16397fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the repository url to work with and prefix for where it will be copied.\n",
    "repo_prefix = './'\n",
    "\n",
    "org='parallelworks'\n",
    "repo_name='dynamic-learning-rivers'\n",
    "repo_url = 'https://github.com/'+org+'/'+repo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198663bf",
   "metadata": {},
   "source": [
    "## Grab data\n",
    "\n",
    "Since the ML runs are on different branches, we need to jump from branch-to-branch and gather and plot data along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4575a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a list of which branches to operate on.\n",
    "# ASSUME that the first branch will have the most\n",
    "# complete list of features (i.e. inputs) to the ML\n",
    "# models. This first list of features will be\n",
    "# used to create a look-up table for feature-to-feature\n",
    "# comparisons/visulizations later.\n",
    "\n",
    "list_branches = ['Nov-2023-log10', 'Nov-2022-log10']\n",
    "list_colors = ['k','r','g','b']\n",
    "fpi_max = 0.0\n",
    "\n",
    "# Initialize empty dataframes\n",
    "# for model scores and histograms\n",
    "model_scores = pd.DataFrame(columns=['hold-out-avg','hold-out-std','ntrain'])\n",
    "train_hist = pd.DataFrame(columns=list_branches)\n",
    "predict_hist = pd.DataFrame(columns=list_branches)\n",
    "\n",
    "# Initialize a plot\n",
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "\n",
    "for ll,branch in enumerate(list_branches):\n",
    "    \n",
    "    # Check for first branch\n",
    "    if ll == 0:\n",
    "        print(\"On first branch; clone, checkout, and build feature integer ID lookup table...\")\n",
    "        ! mkdir -p {repo_prefix}\n",
    "        ! cd {repo_prefix}; git clone {repo_url}\n",
    "        ! cd {repo_prefix}/{repo_name}; git checkout {branch}\n",
    "        \n",
    "        # Load data for look up table only\n",
    "        fpi_avg = pd.read_csv(repo_prefix+repo_name+'/output_data/fpi_avg.csv', index_col=False)\n",
    "        \n",
    "        # Make the loop up table; need to invert\n",
    "        # the keys (integers) with the values (feature names)\n",
    "        # so that feature names can be converted to ints\n",
    "        # later.\n",
    "        feature_id_name_dict = dict((v,k) for k,v in fpi_avg['Unnamed: 0'].to_dict().items())\n",
    "        \n",
    "        # Unload the data b/c later we will want to use the index\n",
    "        del fpi_avg\n",
    "    else:\n",
    "        # Set up is complete with first branch, just change to other branches\n",
    "        ! cd {repo_prefix}/{repo_name}; git checkout {branch}\n",
    "    \n",
    "    # Load data and replace feature names with IDs in dict\n",
    "    # In the process, get a list of features available in\n",
    "    # just this branch.\n",
    "    fpi_avg = pd.read_csv(repo_prefix+repo_name+'/output_data/fpi_avg.csv', index_col=0)\n",
    "    branch_feature_names = list(fpi_avg.index)\n",
    "    fpi_avg.rename(index=feature_id_name_dict, inplace=True)\n",
    "    \n",
    "    fpi_std = pd.read_csv(repo_prefix+repo_name+'/output_data/fpi_std.csv', index_col=0)\n",
    "    fpi_std.rename(index=feature_id_name_dict, inplace=True)\n",
    "    \n",
    "    # Get summary statistics over each FPI (random shuffle\n",
    "    # of grouped features) iteration\n",
    "    upper = fpi_avg.mean(axis=1)+fpi_avg.std(axis=1)\n",
    "    lower = fpi_avg.mean(axis=1)-fpi_avg.std(axis=1)\n",
    "    error = fpi_std.max(axis=1)\n",
    "    \n",
    "    # If the max value is bigger than the current value,\n",
    "    # update it.\n",
    "    if upper.max() > fpi_max:\n",
    "        fpi_max = upper.max()\n",
    "        \n",
    "    # Start printing out good features:\n",
    "    print('Significant features for the ML model on this branch:')\n",
    "    ff = 1\n",
    "    \n",
    "    # Plot a box for each feature. We work feature by feature\n",
    "    # because not all features will be available and not all\n",
    "    # are chopped out from the edges either; sometimes features\n",
    "    # will be chopped out from the middle so we don't want to\n",
    "    # plot continuous lines.\n",
    "    for feature in branch_feature_names:\n",
    "        # Get feature ID from the dict\n",
    "        f_id = feature_id_name_dict[feature]\n",
    "        \n",
    "        # Get the upper and lower bounds of the box\n",
    "        f_upper = upper[f_id] \n",
    "        f_lower = lower[f_id]\n",
    "        f_error = error[f_id]\n",
    "        \n",
    "        #print(f_id)\n",
    "        #print(f_upper)\n",
    "        #print(f_lower)\n",
    "        #print(f_error)\n",
    "        \n",
    "        # Construct the box and plot\n",
    "        # Loop over data points; create box from errors at each point\n",
    "        #rect = plt.Rectangle((f_id - 0.5, f_lower), 1.0, f_upper - f_lower, facecolor=\"black\", alpha=0.1)\n",
    "\n",
    "        left, bottom, width, height = (f_id - 0.5, f_lower, 1.0, f_upper-f_lower)\n",
    "        #print(left)\n",
    "        #print(bottom)\n",
    "        #print(width)\n",
    "        #print(height)\n",
    "        \n",
    "        rect = plt.Rectangle((left, bottom), width, height,\n",
    "            facecolor=list_colors[ll], alpha=0.1)\n",
    "        \n",
    "        # Create patch collection with specified colour/alpha\n",
    "        #pc = PatchCollection(rect, facecolor='r', alpha=0.5, edgecolor='k')\n",
    "    \n",
    "        # Add collection to axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Print out feature name if it is a significant contribution\n",
    "        # (Here, assume that \"significant\" means the lowest bound on\n",
    "        # the FPI improvement ratio is above 1.0)\n",
    "        if f_lower > 1.0:\n",
    "            print(str(ff)+\" --- \"+feature)\n",
    "            ff = ff + 1\n",
    "            \n",
    "    # Clear loaded data\n",
    "    del fpi_std\n",
    "    del fpi_avg\n",
    "    \n",
    "    # Load model scores\n",
    "    # This file summarizes the holdout score for all the\n",
    "    # Superlearners for each ICON-ModEx iteration.\n",
    "    holdout_score = pd.read_csv(\n",
    "        repo_prefix+repo_name+'/output_data/holdout_score.txt', \n",
    "        sep=':', \n",
    "        names=['Value','Number'], \n",
    "        index_col='Value' )\n",
    "    \n",
    "    # This file lists the total number of data available\n",
    "    # (of which 25% is split to the testing set)\n",
    "    input_data = pd.read_csv(repo_prefix+repo_name+'/input_data/WHONDRS_Data.csv')\n",
    "    \n",
    "    model_scores.loc[len(model_scores.index)] = [\n",
    "        holdout_score.loc['Avg',:].values[0],\n",
    "        holdout_score.loc['Std',:].values[0],\n",
    "        len(input_data.index)\n",
    "    ]\n",
    "    \n",
    "    # Grab histograms of the distribution of the target to\n",
    "    # assess bias in the ML models\n",
    "    train_all = pd.read_csv(repo_prefix+repo_name+'/input_data/WHONDRS_Data.csv')\n",
    "    train_hist[branch] = train_all['Normalized_Respiration_Rate_mg_DO_per_H_per_L_sediment']\n",
    "    predict_all = pd.read_csv(repo_prefix+repo_name+'/output_data/unfiltered_predict_output_avg.csv')\n",
    "    predict_hist[branch] = predict_all['Normalized_Respiration_Rate_mg_DO_per_H_per_L_sediment']\n",
    "    \n",
    "# Done with looping over branches\n",
    "ax.grid()\n",
    "\n",
    "plt.xlim(0,len(feature_id_name_dict))\n",
    "plt.ylim(0,fpi_max)\n",
    "\n",
    "plt.xlabel('Feature ID (i.e. input to ML model, no unit)', fontsize=18)\n",
    "plt.ylabel('FPI importance ratio (no unit)', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up side-by-side plot\n",
    "fig, (ax0, ax1)  = plt.subplots(1,2,figsize=(20,5))\n",
    "\n",
    "# Plot progression of model score with training attempt\n",
    "ax0.errorbar(model_scores.index, model_scores['hold-out-avg'],yerr=model_scores['hold-out-std'], fmt='ko')\n",
    "ax0.grid()\n",
    "ax0.set_xlabel('Run ID', fontsize=18)\n",
    "ax0.set_ylabel('ML model score (R^2)', fontsize=18)\n",
    "\n",
    "# Plot progression of histograms (for bias) with training attempt\n",
    "nbin = 25\n",
    "for bb,branch in enumerate(list_branches):\n",
    "    # Histogram for training set truth reference\n",
    "    n, bins, patches = ax1.hist(\n",
    "            np.log10(np.abs(train_hist[branch])),\n",
    "            nbin, density=True, histtype=\"stepfilled\", linestyle=('dashed'), color=('gray'), alpha=0.5)\n",
    "    \n",
    "    # Histogram for predictions\n",
    "    n, bins, patches = ax1.hist(\n",
    "            np.log10(np.abs(predict_hist[branch])),\n",
    "            nbin, density=True, histtype=\"step\", linestyle=('solid'), color=(list_colors[bb]), linewidth=3)\n",
    "    \n",
    "ax1.grid()\n",
    "ax1.set_ylabel('Frequency (counts)', fontsize=18)\n",
    "ax1.set_xlabel('Log10 of respiration rate (log10(mg O2/L/hr))', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848090a8-795e-49d8-8686-f0ad86767134",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_id_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35eef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
